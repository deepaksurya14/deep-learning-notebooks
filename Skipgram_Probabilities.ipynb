{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "561c997c",
      "metadata": {
        "id": "561c997c"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "START = 'START'\n",
        "STOP = 'STOP'\n",
        "k = 1\n",
        "\n",
        "# This is the training data\n",
        "x1 = 'START a b c STOP'\n",
        "x2 = 'START a c d STOP'\n",
        "x3 = 'START b d e a STOP'\n",
        "\n",
        "V = set()\n",
        "\n",
        "_FILL_IN_ = 'FILL IN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a0a80a45",
      "metadata": {
        "id": "a0a80a45"
      },
      "outputs": [],
      "source": [
        "# Get the relevant counts\n",
        "S = [x1, x2, x3]\n",
        "count_2 = defaultdict(int)\n",
        "count_1 = defaultdict(int)\n",
        "theta_1 = defaultdict(float)\n",
        "theta = defaultdict(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "290eac09",
      "metadata": {
        "id": "290eac09"
      },
      "outputs": [],
      "source": [
        "# Split the data and get what you need\n",
        "for x in S:\n",
        "    words = x.split()  # Split the sentence into words\n",
        "    for word in words:\n",
        "        V.add(word)  # Add the word to the vocabulary set\n",
        "    for i in range(len(words) - 1):\n",
        "        count_2[(words[i], words[i + 1])] += 1  # Count bigrams\n",
        "        count_1[words[i]] += 1  # Count unigrams\n",
        "    count_1[words[-1]] += 1  # Count the last word of the sentence for unigrams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "0ace5d77",
      "metadata": {
        "id": "0ace5d77"
      },
      "outputs": [],
      "source": [
        "assert(len(V) == 7)\n",
        "V.remove(START)\n",
        "# Unigram ML estimates\n",
        "# Note that START should not be a key\n",
        "# Don't remove START from count_1 as we will need it in the demoninator\n",
        "for u in V:\n",
        "    theta_1[u] = count_1[u] / (sum(count_1.values()) - count_1[START])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d6437b43",
      "metadata": {
        "id": "d6437b43"
      },
      "outputs": [],
      "source": [
        "# Remove START and STOP form the dictionary - these are not true words\n",
        "V.discard(STOP)\n",
        "V.discard(START)\n",
        "assert(len(V) == 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a1d921b7",
      "metadata": {
        "id": "a1d921b7"
      },
      "outputs": [],
      "source": [
        "# Get the smoothed estimates\n",
        "for u in V:\n",
        "    for v in V | set([STOP]):\n",
        "        theta[(u, v)] = (count_2[(u, v)] + k*theta_1[v]) / (count_1[u] + k)\n",
        "\n",
        "\n",
        "# For u = START, get the smoothed probabilities\n",
        "for v in V | set([STOP]):\n",
        "    theta[(START, v)] = (count_2[(START, v)] + k*theta_1[v]) / (count_1[START] + k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b10879b1",
      "metadata": {
        "id": "b10879b1"
      },
      "outputs": [],
      "source": [
        "# Check that the sum is 1, as it should be\n",
        "for u in V | set([START]):\n",
        "    p_sum = 0.0\n",
        "    p_sum_1 = 0.0\n",
        "    for v in V | set([STOP]):\n",
        "        p_sum += theta[(u, v)]\n",
        "        p_sum_1 += theta_1[v]\n",
        "    p_sum_1 += theta_1[START]\n",
        "    assert(abs(p_sum_1 - 1.0) ** 2 <= 0.00001)\n",
        "    assert(abs(p_sum - 1.0) ** 2 <= 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d8f5dd3d",
      "metadata": {
        "id": "d8f5dd3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a3cc9e-f336-4328-90dc-23c9c1e91590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary V: {'b', 'a', 'd', 'e', 'c'}\n",
            "Unigram probabilities theta_1:\n",
            "P(STOP) = 0.23076923076923078\n",
            "P(b) = 0.15384615384615385\n",
            "P(a) = 0.23076923076923078\n",
            "P(d) = 0.15384615384615385\n",
            "P(e) = 0.07692307692307693\n",
            "P(c) = 0.15384615384615385\n",
            "P(START) = 0.0\n",
            "Smoothed Bigram probabilities theta:\n",
            "P(b|STOP) = 0.07692307692307693\n",
            "P(b|b) = 0.05128205128205129\n",
            "P(b|d) = 0.3846153846153846\n",
            "P(b|e) = 0.025641025641025644\n",
            "P(b|c) = 0.3846153846153846\n",
            "P(b|a) = 0.07692307692307693\n",
            "P(a|STOP) = 0.3076923076923077\n",
            "P(a|b) = 0.28846153846153844\n",
            "P(a|d) = 0.038461538461538464\n",
            "P(a|e) = 0.019230769230769232\n",
            "P(a|c) = 0.28846153846153844\n",
            "P(a|a) = 0.057692307692307696\n",
            "P(d|STOP) = 0.4102564102564103\n",
            "P(d|b) = 0.05128205128205129\n",
            "P(d|d) = 0.05128205128205129\n",
            "P(d|e) = 0.358974358974359\n",
            "P(d|c) = 0.05128205128205129\n",
            "P(d|a) = 0.07692307692307693\n",
            "P(e|STOP) = 0.11538461538461539\n",
            "P(e|b) = 0.07692307692307693\n",
            "P(e|d) = 0.07692307692307693\n",
            "P(e|e) = 0.038461538461538464\n",
            "P(e|c) = 0.07692307692307693\n",
            "P(e|a) = 0.6153846153846154\n",
            "P(c|STOP) = 0.4102564102564103\n",
            "P(c|b) = 0.05128205128205129\n",
            "P(c|d) = 0.3846153846153846\n",
            "P(c|e) = 0.025641025641025644\n",
            "P(c|c) = 0.05128205128205129\n",
            "P(c|a) = 0.07692307692307693\n",
            "P(START|STOP) = 0.057692307692307696\n",
            "P(START|b) = 0.28846153846153844\n",
            "P(START|d) = 0.038461538461538464\n",
            "P(START|e) = 0.019230769230769232\n",
            "P(START|c) = 0.038461538461538464\n",
            "P(START|a) = 0.5576923076923077\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary V:\", V)\n",
        "\n",
        "print(\"Unigram probabilities theta_1:\")\n",
        "for word, unigram_prob in theta_1.items():\n",
        "    print(f\"P({word}) = {unigram_prob}\")\n",
        "\n",
        "print(\"Smoothed Bigram probabilities theta:\")\n",
        "for bigram, bigram_prob in theta.items():\n",
        "    print(f\"P({bigram[0]}|{bigram[1]}) = {bigram_prob}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "likelihood = 1\n",
        "log_likelihood = 0\n",
        "\n",
        "for x in S:\n",
        "    words = x.split()\n",
        "    bigrams = zip(words, words[1:])\n",
        "\n",
        "    likelihood *= np.prod([theta[bigram] for bigram in bigrams])\n",
        "    log_likelihood += np.sum([np.log(theta[bigram]) for bigram in bigrams])\n"
      ],
      "metadata": {
        "id": "x8PhqjSiylUy"
      },
      "id": "x8PhqjSiylUy",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specific_bigrams_counts = {\n",
        "    ('START', 'a'): count_2[('START', 'a')],\n",
        "    ('b', 'c'): count_2[('b', 'c')],\n",
        "    ('a', 'e'): count_2[('a', 'e')]\n",
        "}\n"
      ],
      "metadata": {
        "id": "__a_abUQy6Vz"
      },
      "id": "__a_abUQy6Vz",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Likelihood:\", likelihood)\n",
        "print(\"Log Likelihood:\", log_likelihood)\n",
        "print(\"Counts for specific bigrams:\", specific_bigrams_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "502sx6xVy8XU",
        "outputId": "64ae6f94-0261-4440-d274-745c14c73c08"
      },
      "id": "502sx6xVy8XU",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Likelihood: 4.859263663359929e-06\n",
            "Log Likelihood: 0.0\n",
            "Counts for specific bigrams: {('START', 'a'): 2, ('b', 'c'): 1, ('a', 'e'): 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPWF1QRWy-as"
      },
      "id": "zPWF1QRWy-as",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}